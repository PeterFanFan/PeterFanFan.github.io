<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="Sign Language Generation, Emotion, Sign-HADiff">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Sign-HADiff</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Sign-HADiff: Hierarchical Attention Diffusion Model for Sign Language Generation</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <strong>Guanwen Feng </strong> </a><sup>1,2,3†</sup>,</span>
            
            </span>
            <span class="author-block">
             <a href="https://faculty.xidian.edu.cn/MQG1/zh_CN/index.htm"> Qiguang Miao</a><sup>1,2,3*</sup>,
            </span>

            <span class="author-block">
              <strong>An Liu</strong><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://faculty.xidian.edu.cn/LIYUNAN/zh_CN/index/413869/list/index.htm"> Yunan Li </a><sup>1,2,3</sup>,
            </span>
            <span class="author-block">
              <strong>Yilin Zhang</strong><sup>1,2,3</sup>,
            </span>
      <span class="author-block">
              <strong>Junwei Jing</strong><sup>1,2,3</sup>,
            </span>
      <span class="author-block">
              <strong>Jianxin Ma</strong><sup>4</sup>,

              <span class="author-block">
                <a href="https://faculty.xidian.edu.cn/XK2/zh_CN/index.htm">Kun Xie</a><sup>1,2,3</sup>,
              </span>
            <span class="author-block">
              <a href="https://cmpun.github.io/">Chi-Man Pun</a><sup>5</sup>
            </span>
       
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of Computer Science and Technology, Xidian University,  China</span>
            <span class="author-block"><sup>2</sup>Xi’an Key Laboratory of Big Data and Intelligent Vision, Xidian University, China</span>
            <span class="author-block"><sup>3</sup>Key Laboratory of Collaborative Intelligence Systems, Ministry of Education, Xidian University, China</span>
            <span class="author-block"><sup>4</sup>School of Computer Science and Engineering, Sun Yat-sen University, China</span>
            <span class="author-block"><sup>5</sup>Department of Computer and Information Science, University of Macau, Macao 999078, China</span>


          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
      

              <!-- Video Link. -->
              <span class="link-block">
                <a href="#teaser"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/zyl1042919014/sign-hadiff"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay loop controls playsinline height="100%">
        <source src="./static/videos/video1.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <strong> Sign-HADiff</strong> A novel sign language generation framework, Sign-HADiff, uses the sign language latent space predicted by Gloss as a condition to guide the diffusion model to generate highly semantic and accurate sign language sequences. </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
        <br>
        <br>
         Sign language generation technology plays a crucial role in facilitating communication between deaf and hearing individuals. Current methods primarily utilize Transformers and GANs for generation; however, these methods often face issues with insufficient accuracy and semantic information, resulting in incomprehensible sign language keypoints. This problem arises because existing approaches mainly focus on directly mapping text sequences to skeletal point sequences, emphasizing sequence-to-sequence tasks while neglecting the representation of sign language skeletal points. To address these problems, we propose a self-supervised, two-stage generative framework called Sign-HADiff, which divides sign language generation into two stages. In the reconstruction stage, HAUnet-Diffusion learns the representation of skeletal points through self-supervised learning. In the generation stage, it uses the sign language latent space predicted by the Gloss-Based Latent Space Predictor (GLSP) as a condition to guide HAUnet-Diffusion in generating sign language sequences with more precise skeletal points and higher semantic accuracy. Sign-HADiff consists of two components:  
1. HAUnet-Diffusion: We designed a Hierarchical Attention Unet (HAUnet) to replace the Unet structure in Denoising Diffusion Probabilistic Models (DDPM). In HAUnet, we introduced Spatial Augmentation Attention (SAA) and Hierarchical Feature Integration (HFI) to enhance the spatial perceptual information across different feature layers, obtaining more comprehensive skeletal point features and reducing information loss within the Unet structure. 2. GLSP: We developed a Gloss Semantic Enhancer (GSE) that combines a Regional Feature Extractor and a Global Perceptron within GLSP to acquire a semantically richer latent space representation of sign language. Experimental results on the PHOENIX and How2Sign datasets demonstrate that Sign-HADiff generates more accurate sign language skeletal points and outperforms existing methods on standard metrics.
          </p>
        </div>
      </div>
    </div>
    <br>

    
    <!-- Proposed Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Proposed Method</h2>
        <div class="content has-text-justified">
        <br>
        <br>
          <img src="./static/videos/signhadiff.png" alt="signhadiff">

          <p>
            <br>

            Overview. The Sign-HADiff consists of two main modules: GLSP , and HAUnet-Diffusion. It aims to predict sign language latent space by GLSP and feed them into HAUnet-Diffusion to guide the generation of sign language.
        <br>
              <br>
        
          </p>
          <p>
            <img src="./static/videos/HAUnet-Diffusion.png" alt="signhadiff">
    <br>
    
          </p>
Structure of HAUnet-Diffusion. The model consists of two parts: the Pose Pre-processing for obtaining the latent space representation corresponding to the sign language, and the HAUnet for predicting the noise added at moment t.
    <br>
    
          <p>
    <br>
    
                        <img src="./static/videos/HAUnet.png" alt="signhadiff">

          </p>

          </p>
    <br>
Structure of HAUnet. The model enhances the representation of sign language skeletal points for each downsample feature by Spatial Augmentation Attention and aggregates the feature data information after SAA by Hierarchical Feature Integration (HFI) to ensure richer and more accurate information about the location of the sign language skeletal points during the upsample process.
          <p>
        </div>
      </div>
    </div>
    <!--/ Proposed Method. -->  
</section>



 



<footer class="footer">
  <div class="container">
      <div class="content has-text-centered">
          <a class="icon-link" href="xx">
              <i class="fas fa-file-pdf"></i>
          </a>
          <a class="icon-link" href="xx" class="external-link" disabled>
              <i class="fab fa-github"></i>
          </a>
      </div>
      <div class="columns is-centered">
          <div class="column is-8">
              <div class="content">
                  <p style="text-align:center">
                    This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                  </p>
                  <p style="text-align:center">
                    Website source code based on the <a
                    href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
                  </p>

              </div>
          </div>
      </div>
  </div>
</footer>

</body>
</html>
